knitr::include_graphics("sigmoid.jpg")
knitr::include_graphics("graph.png")
knitr::include_graphics("threshold.jpg")
library("readxl") #importing stata data file
library("dplyr")
library("stats")
library("GGally")
library("ROCR")
library("ggpubr")
library("tidyverse") #for data manipulation and visualization
library("ggplot2")
library("tidyr")
admit_data <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
#convert the numerical values for categorical variables to factors
admit_data$admit <- factor(admit_data$admit,
levels=c(0,1),
labels=c("No", "Yes"))
admit_data$rank <- factor(admit_data$rank,
levels=c(1,2,3,4),
labels=c("veryHigh", "high", "medium", "low"))
admit_data
# Use the function select_if() from the dplyr library to
# select only the numerical columns
continuous <-select_if(admit_data, is.numeric)
# Print the summary statistic
summary(continuous)
# Histogram with kernel density curve
ggplot(continuous, aes(x = gre)) +
geom_density(alpha = .2, fill = "#FF6666")
# Compute the value of the bottom 3% percent of GRE scores
bottom_percent <- quantile(admit_data$gre, 0.03)
bottom_percent
# drop the observations above this threshold
admit_drop <-admit_data %>%
filter(gre>bottom_percent)
ggplot(admit_drop, aes(x = gre)) +
geom_density(alpha = .2, fill = "#FF6666")
admit_rescale <- admit_drop %>%
mutate_if(is.numeric, funs(as.numeric(scale(.))))
head(admit_rescale)
# Store the factor columns in factor in a data frame type.
factor <- data.frame(select_if(admit_rescale, is.factor))
ncol(factor)
# Create graph for each column by automatizing the graphing process
graph <- lapply(names(factor),
function(x)
ggplot(factor, aes(get(x))) +
geom_bar() +
theme(axis.text.x = element_text(angle = 90)))
graph # print the 2 graphs we produced
table(admit_rescale$rank)
ggplot(admit_rescale, aes(x = rank, fill = admit)) +
geom_bar(position = "fill") +
theme_classic()
ggplot(admit_rescale, aes(x = admit, y = gre)) +
geom_boxplot() +
stat_summary(fun = mean,
geom = "point",
size = 3,
color = "steelblue") +
theme_classic()
ggplot(admit_rescale, aes(x = admit, y = gpa)) +
geom_boxplot() +
stat_summary(fun = mean,
geom = "point",
size = 3,
color = "steelblue") +
theme_classic()
# Plot distribution working time by education
ggplot(admit_rescale, aes(x = gre)) +
geom_density(aes(color = rank), alpha = 0.5) +
theme_classic()
ggplot(admit_rescale, aes(x = gpa)) +
geom_density(aes(color = rank), alpha = 0.5) +
theme_classic()
ggplot(admit_rescale, aes(x = gpa, y = gre)) +
geom_point(aes(color = admit),
size = 0.5) +
stat_smooth(method = 'lm',
formula = y~poly(x, 2),
se = TRUE,
aes(color = admit)) +
theme_classic()
ggplot(admit_rescale, aes(x = gpa, y = gre)) +
geom_point(aes(color = rank),
size = 0.5) +
stat_smooth(method = 'lm',
formula = y~poly(x, 2),
se = TRUE,
aes(color = rank)) +
theme_classic()
# Convert data to numeric
corr <- data.frame(lapply(admit_rescale, as.integer))
# plot the heat map with the following arguments:
ggcorr(corr,
method = c("pairwise", "spearman"), # compute the correlation
nbreaks = 6, # Number of break
hjust = 0.8, # Control position of the variable name in the plot
label = TRUE, # Add labels in the center of the windows
label_size = 3, # Size labels
color = "grey50") # Color of the label
set.seed(1234)
create_train_test <- function(data, size = 0.8, train = TRUE) {
n_row = nrow(data)
total_row = size * n_row
train_sample <- 1: total_row
if (train == TRUE) {
return (data[train_sample, ])
} else {
return (data[-train_sample, ])
}
}
data_train <- create_train_test(admit_rescale, 0.8, train = TRUE)
data_test <- create_train_test(admit_rescale, 0.8, train = FALSE)
dim(data_train)
dim(data_test)
formula <- admit~.
logit <- glm(formula, data = data_train, family = 'binomial')
summary(logit)
summary(logit)
logit$coef
b0 <- logit$coef[1] # intercept
gre <- logit$coef[2]
gpa <- -logit$coef[3]
rankhigh <- logit$coef[4]
rankmedium <- logit$coef[5]
ranklow <- logit$coef[6]
gre_range <- seq(from=min(data_train$gre), to=max(data_train$gre), by=.01)
gpa_val <- mean(data_train$gpa)
a_logits <- b0 +
gre*gre_range +
gpa*gpa_val +
rankhigh*0 +
rankmedium*0 +
ranklow * 0
b_logits <- b0 +
gre*gre_range +
gpa*gpa_val +
rankhigh*1 +
rankmedium*0 +
ranklow * 0
c_logits <- b0 +
gre*gre_range +
gpa*gpa_val +
rankhigh*0 +
rankmedium*1 +
ranklow * 0
d_logits <- b0 +
gre*gre_range +
gpa*gpa_val +
rankhigh*0 +
rankmedium*0 +
ranklow *1
# Compute the probibilities (this is what will actually get plotted):
a_probs <- exp(a_logits)/(1 + exp(a_logits))
b_probs <- exp(b_logits)/(1 + exp(b_logits))
c_probs <- exp(c_logits)/(1 + exp(c_logits))
d_probs <- exp(d_logits)/(1 + exp(d_logits))
plot.data <- data.frame(a=a_probs, b=b_probs, c=c_probs, d=d_probs, X1=gre_range)
plot.data <- gather(plot.data, key=group, value=prob, a:d)
head(plot.data)
ggplot(plot.data, aes(x=X1, y=prob, color=group)) + # asking it to set the color by the variable "group" is what makes it draw three different lines
geom_line(lwd=2) +
labs(x="X1", y="P(Admission rate)", title="Probability of getting accepted")
summary(logit)
lapply(logit, class)[1:3]
logit$coefficients
summary(logit)$coef
predict <- predict(logit, data_test, type = 'response')
# confusion matrix
table_mat <- table(data_test$admit, predict > 0.5)
table_mat
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test
precision <- function(matrix) {
# True positive
tp <- matrix[2, 2]
# false positive
fp <- matrix[1, 2]
return (tp / (tp + fp))
}
recall <- function(matrix) {
# true positive
tp <- matrix[2, 2]# false positive
fn <- matrix[2, 1]
return (tp / (tp + fn))
}
prec <- precision(table_mat)
prec
rec <- recall(table_mat)
rec
f1 <- 2 * ((prec * rec) / (prec + rec))
f1
library(ROCR)
ROCRpred <- prediction(predict, data_test$admit)
ROCRperf <- performance(ROCRpred, 'tpr', 'fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2, 1.7))
