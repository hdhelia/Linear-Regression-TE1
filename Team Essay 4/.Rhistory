knitr::include_graphics("KNN.JPG")
Ingredient <- c("Monster","ACTIV","Pepsi","Vodka")
Sweetness <- c(8,9,4,2)
Fizziness <- c(8,1,8,1)
Typeofdrink <- c("Energy booster","Healthy drink","Cold drink","Hard drink")
example <- data.frame(Ingredient,Sweetness,Fizziness,Typeofdrink)
example
knitr::include_graphics("intropic.png")
knitr::include_graphics("EuclideanDistanceGraphic.jpeg")
Maaza <- c(8,2)
distance <- function(a,b,c,d){
return(sqrt(as.double(((a-c)*(a-c)+(b-d)*(b-d)))))
}
distan <- c()
by(example, seq_len(nrow(example)), function(row){
distan <<- c(distan,
distance(as.integer(row[2]), as.integer(row[3]),8,2))
})
example$maaza <- distan
example
library("dplyr")
library("readr")
library("stats")
library("GGally")
library("ggpubr")
library("tidyverse") #for data manipulation and visualization
library("class")
library("gmodels")
iris <- read.csv("Iris.csv", stringsAsFactors = TRUE) %>%
select(-"Id") %>%
drop_na() %>% #remove NA values
distinct() # remove duplicated rows
summary(iris)
set.seed(99) #randomize the dataset to avoid heavily discarding one species during data split
rows <- sample(nrow(iris))
iris <- iris[rows, ] # this is the randomized data set with jumbled rows
normalize <- function(x) {
return ( (x - min(x)) / (max(x) - min(x)) )
}
iris_norm <- as.data.frame(lapply(iris[1:4], normalize))
# you can check to see if it's been properly normalized
summary(iris_norm)
iris.train<- iris_norm[1:103,]
iris.test<- iris_norm[104:147,]
iris_train_labels <- iris[1:103, 5]
iris_test_labels <- iris[104:147, 5]
A <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=SepalLengthCm, fill=Species),
show.legend = FALSE) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
B <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=SepalWidthCm, fill=Species)) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal")
ggarrange(A, B,
ncol = 2, nrow = 1)
C <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=PetalLengthCm, fill=Species),
show.legend = FALSE) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
D <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=PetalWidthCm, fill=Species)) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal")
ggarrange(C, D,
ncol = 2, nrow = 1)
sepal1 <- ggplot(data = iris,
aes(x = SepalLengthCm, y = SepalWidthCm, color = Species)) +
geom_point() +
geom_smooth() +
theme(
legend.position = "bottom",
legend.direction = "horizontal")
sepal2 <- ggplot(data = iris, aes(x = SepalLengthCm, y = SepalWidthCm)) +
geom_point(size = 3) +
geom_smooth(size = 1, se = FALSE) +
facet_grid(rows = vars(Species))
ggarrange(sepal1, sepal2,
ncol = 2, nrow = 1)
petal1 <- ggplot(data = iris,
aes(x = PetalLengthCm, y = PetalWidthCm, color = Species)) +
geom_point() +
geom_smooth() +
theme(
legend.position = "bottom",
legend.direction = "horizontal")
petal2 <- ggplot(data = iris, aes(x = PetalLengthCm, y = PetalWidthCm)) +
geom_point(size = 3) +
geom_smooth(size = 1, se = FALSE) +
facet_grid(rows = vars(Species))
ggarrange(petal1, petal2,
ncol = 2, nrow = 1)
size <- NROW(iris_train_labels) #size of training data
size
sqrt(size) # the k-value
#library(class)
iris_k9_pred <- knn(
train = iris.train,
test = iris.test,
cl = iris_train_labels,
k=9
)
iris_k11_pred <- knn(
train = iris.train,
test = iris.test,
cl = iris_train_labels,
k=11
)
iris_k3_pred <- knn(
train = iris.train,
test = iris.test,
cl = iris_train_labels,
k=3
)
#k=3
CrossTable(x = iris_k3_pred ,y = iris_test_labels)
#k=9
CrossTable(x = iris_k9_pred ,y = iris_test_labels)
#k=11
CrossTable(x = iris_k11_pred ,y = iris_test_labels)
KNN_func <- function(train, test, train.label, k){
return(knn(train, test, train.label, k))
}
accuracy <- function(train, test, train.label, test.label) {
accuracy_val <- c()
for (k in 1:30) {
Knn.pred <- KNN_func(train, test, train.label, k)
accuracy_val[k] <- 100 * sum(test.label == Knn.pred)/NROW(test.label)
}
return(accuracy_val)
}
k <- 1:30
acc <- accuracy(iris.train, iris.test, iris_train_labels, iris_test_labels)
ggplot(mapping = aes(x=k, y=acc)) +
geom_point() +
geom_line() +
xlab("k-value") +
ylab("Accuracy")
knitr::include_graphics("KNN.JPG")
Ingredient <- c("Monster","ACTIV","Pepsi","Vodka")
Sweetness <- c(8,9,4,2)
Fizziness <- c(8,1,8,1)
Typeofdrink <- c("Energy booster","Healthy drink","Cold drink","Hard drink")
example <- data.frame(Ingredient,Sweetness,Fizziness,Typeofdrink)
example
knitr::include_graphics("intropic.png")
knitr::include_graphics("EuclideanDistanceGraphic.jpeg")
Maaza <- c(8,2)
distance <- function(a,b,c,d){
return(sqrt(as.double(((a-c)*(a-c)+(b-d)*(b-d)))))
}
distan <- c()
by(example, seq_len(nrow(example)), function(row){
distan <<- c(distan,
distance(as.integer(row[2]), as.integer(row[3]),8,2))
})
example$maaza <- distan
example
library("dplyr")
library("readr")
library("stats")
library("GGally")
library("ggpubr")
library("tidyverse") #for data manipulation and visualization
library("class")
library("gmodels")
iris <- read.csv("Iris.csv", stringsAsFactors = TRUE) %>%
select(-"Id") %>%
drop_na() %>% #remove NA values
distinct() # remove duplicated rows
summary(iris)
set.seed(99) #randomize the dataset to avoid heavily discarding one species during data split
rows <- sample(nrow(iris))
iris <- iris[rows, ] # this is the randomized data set with jumbled rows
normalize <- function(x) {
return ( (x - min(x)) / (max(x) - min(x)) )
}
iris_norm <- as.data.frame(lapply(iris[1:4], normalize))
# you can check to see if it's been properly normalized
summary(iris_norm)
iris.train<- iris_norm[1:103,]
iris.test<- iris_norm[104:147,]
iris_train_labels <- iris[1:103, 5]
iris_test_labels <- iris[104:147, 5]
A <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=SepalLengthCm, fill=Species),
show.legend = FALSE) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
B <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=SepalWidthCm, fill=Species)) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal")
ggarrange(A, B,
ncol = 2, nrow = 1)
C <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=PetalLengthCm, fill=Species),
show.legend = FALSE) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
D <- iris %>%
ggplot() +
geom_boxplot(aes(x=Species, y=PetalWidthCm, fill=Species)) +
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
legend.position = "bottom",
legend.direction = "horizontal")
ggarrange(C, D,
ncol = 2, nrow = 1)
sepal1 <- ggplot(data = iris,
aes(x = SepalLengthCm, y = SepalWidthCm, color = Species)) +
geom_point() +
geom_smooth() +
theme(
legend.position = "bottom",
legend.direction = "horizontal")
sepal2 <- ggplot(data = iris, aes(x = SepalLengthCm, y = SepalWidthCm)) +
geom_point(size = 3) +
geom_smooth(size = 1, se = FALSE) +
facet_grid(rows = vars(Species))
ggarrange(sepal1, sepal2,
ncol = 2, nrow = 1)
petal1 <- ggplot(data = iris,
aes(x = PetalLengthCm, y = PetalWidthCm, color = Species)) +
geom_point() +
geom_smooth() +
theme(
legend.position = "bottom",
legend.direction = "horizontal")
petal2 <- ggplot(data = iris, aes(x = PetalLengthCm, y = PetalWidthCm)) +
geom_point(size = 3) +
geom_smooth(size = 1, se = FALSE) +
facet_grid(rows = vars(Species))
ggarrange(petal1, petal2,
ncol = 2, nrow = 1)
size <- NROW(iris_train_labels) #size of training data
size
sqrt(size) # the k-value
#library(class)
iris_k9_pred <- knn(
train = iris.train,
test = iris.test,
cl = iris_train_labels,
k=9
)
iris_k11_pred <- knn(
train = iris.train,
test = iris.test,
cl = iris_train_labels,
k=11
)
iris_k3_pred <- knn(
train = iris.train,
test = iris.test,
cl = iris_train_labels,
k=3
)
#k=3
CrossTable(x = iris_k3_pred ,y = iris_test_labels)
#k=9
CrossTable(x = iris_k9_pred ,y = iris_test_labels)
#k=11
CrossTable(x = iris_k11_pred ,y = iris_test_labels)
KNN_func <- function(train, test, train.label, k){
return(knn(train, test, train.label, k))
}
accuracy <- function(train, test, train.label, test.label) {
accuracy_val <- c()
for (k in 1:30) {
Knn.pred <- KNN_func(train, test, train.label, k)
accuracy_val[k] <- 100 * sum(test.label == Knn.pred)/NROW(test.label)
}
return(accuracy_val)
}
k <- 1:30
acc <- accuracy(iris.train, iris.test, iris_train_labels, iris_test_labels)
ggplot(mapping = aes(x=k, y=acc)) +
geom_point() +
geom_line() +
xlab("k-value") +
ylab("Accuracy")
